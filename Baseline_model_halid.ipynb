{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "offical_trainX = pd.read_csv(\"./data/dengue_features_train.csv\")\n",
    "offical_trainY = pd.read_csv(\"./data/dengue_labels_train.csv\")\n",
    "\n",
    "trimmed_trainX=offical_trainX.drop(['week_start_date'], axis=1)\n",
    "trimmed_trainY=offical_trainY.drop(['year', 'weekofyear'], axis=1)\n",
    "\n",
    "sj_official_trainX= trimmed_trainX[trimmed_trainX.city == \"sj\"]\n",
    "iq_official_trainX= trimmed_trainX[trimmed_trainX.city == \"iq\"]\n",
    "\n",
    "sj_len_X=len(sj_official_trainX)\n",
    "iq_len_X=len(iq_official_trainX)\n",
    "\n",
    "sj_trainX=sj_official_trainX[:749]\n",
    "iq_trainX=iq_official_trainX[:416]\n",
    "\n",
    "sj_testX=sj_official_trainX[749:]\n",
    "iq_testX=iq_official_trainX[416:]\n",
    "\n",
    "sj_official_trainY= trimmed_trainY[trimmed_trainY.city == \"sj\"]\n",
    "iq_official_trainY= trimmed_trainY[trimmed_trainY.city == \"iq\"]\n",
    "\n",
    "sj_len_Y=len(sj_official_trainY)\n",
    "iq_len_Y=len(sj_official_trainY)\n",
    "\n",
    "sj_trainY=sj_official_trainY[:749]\n",
    "iq_trainY=iq_official_trainY[:416]\n",
    "\n",
    "sj_testY=sj_official_trainY[749:]\n",
    "iq_testY=iq_official_trainY[416:]\n",
    "\n",
    "trainX = pd.concat((sj_trainX, iq_trainX), axis=0)\n",
    "trainY = pd.concat((sj_trainY, iq_trainY), axis=0)\n",
    "testX = pd.concat((sj_testX, iq_testX), axis=0)\n",
    "testY = pd.concat((sj_testY, iq_testY), axis=0)\n",
    "\n",
    "trainY=trainY.drop('city', axis=1)\n",
    "testY=testY.drop('city', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 MAE: 13.12235664654482\n",
      "Average MAE: 13.12235664654482\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "all_numerical_features = trainX.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "all_categorical_features = trainX.select_dtypes(include=[object]).columns\n",
    "numerical_features = [value for value in all_numerical_features]\n",
    "categorical_features = [value for value in all_categorical_features]\n",
    "\n",
    "total_abs_error = 0\n",
    "runtime_amount = 30\n",
    "\n",
    "def best_pipeline_intown(trainX, trainY, testX): ### returns predicted Y\n",
    "\n",
    "    # Preprocessing for numerical data\n",
    "    numerical_transformer = Pipeline(\n",
    "        steps=[(\"imputer\", KNNImputer(n_neighbors=5)), \n",
    "               (\"scaler\", StandardScaler())]\n",
    "    )\n",
    "    # Preprocessing for categorical data\n",
    "    categorical_transformer = OneHotEncoder()\n",
    "\n",
    "    # Bundle Preprocessing for numerical and categorical data\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", numerical_transformer, numerical_features),\n",
    "            (\"cat\", OneHotEncoder(), categorical_features),\n",
    "        ],\n",
    "        remainder=\"passthrough\",\n",
    "    )\n",
    "\n",
    "    model = RandomForestRegressor(n_estimators=300, max_depth=5)\n",
    "    # model = SVR()\n",
    "\n",
    "    pipeline = Pipeline([(\"preprocessor\", preprocessor), (\"regressor\", model)])\n",
    "    pipeline.fit(trainX, trainY)\n",
    "    predicted_Y = pipeline.predict(testX)\n",
    "    \n",
    "    return predicted_Y\n",
    "\n",
    "for i in range(runtime_amount):\n",
    "    predicted_Y = best_pipeline_intown(trainX, trainY, testX)\n",
    "    \n",
    "    absolute_error = mean_absolute_error(testY, predicted_Y)\n",
    "    total_abs_error += absolute_error\n",
    "    print(i + 1, \"MAE:\", absolute_error)\n",
    "\n",
    "print(\"Average MAE:\", total_abs_error / runtime_amount)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
